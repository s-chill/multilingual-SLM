RAPOSA is a robot for Search and Rescue (SAR) operations, designed to operate in outdoors hazardous environments, such as debris resulting from structure collapses. At this stage, the robot is equipped for search operations only, defined as the tele-operated detection of victims, using specific sensors, whose information is transmitted to the remote operator. The robot equipment (sensors) may be adapted to the specific needs. At the moment it includes 3 conventional cameras, one thermal camera, several explosive and toxic gas sensors, temperature and humidity sensors, inclinometers, artificial lights, microphone and speakers. The robot dimensions are length: 75 cm, width: 37 cm, height: 17,5 cm and weight: 27 kg.

The RAPOSA robot was developed by a consortium led by the company IDMind, together with ISR/IST, the Lisbon firefighters brigade, and the University of South California. It was financed by AdI and POSI.

The robot is semi-autonomous, i.e., it is tele-operated via a wireless link from a remote console using a conventional GUI and a gamepad, but can simultaneously display the capacity to carry out short tasks autonomously. The robot can execute commands sent by a team of SAR experts, located in a safe place. During task execution, the robot is able to process the information from different sensors to the remote command station, so as to provide the human team with relevant information on its surrounding environment (terrain conditions, temperature, dangerous gases, water or heat sources, either from human victims or not). The robot has small dimensions and weight. It is tolerant to impact, dust and humidity and its all terrain capable, namely it can climb stairs. Moreover, it can be lifted by a cable, to facilitate deployment from a height (e.g., into a pipeline).

Research is currently being carried out with the aim of endowing RAPOSA with a higher degree of autonomy, meaning that certain operations requiring manual operation can be done autonomously by the robot. These include: autonomous stair climbing, autonomous docking, and preventive stop after hole detection. Moreover, human–robot interaction issues are also being tackled by improving the operator interface, namely exploring augmented reality techniques.