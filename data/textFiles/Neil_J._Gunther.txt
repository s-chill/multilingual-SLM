Neil Gunther (born 15 August 1950) is a computer information systems researcher best known internationally for developing the open-source performance modeling software Pretty Damn Quick and developing the Guerrilla approach to computer capacity planning and performance analysis. He has also been cited for his contributions to the theory of large transients in computer systems and packet networks , and his universal law of computational scalability .

Gunther is a Senior Member of both the Association for Computing Machinery (ACM) and the Institute of Electrical and Electronics Engineers (IEEE), as well as a member of the American Mathematical Society (AMS), American Physical Society (APS), Computer Measurement Group (CMG) and ACM SIGMETRICS .

He is currently focused on developing quantum information system technologies.

Gunther is an Australian of German and Scots ancestry, born in Melbourne on 15 August 1950. He attended Preston East Primary School from 1955 to 1956, and Balwyn North Primary School from 1956 until 1962. For his tenth birthday, Gunther received a copy of the now famous book entitled The Golden Book of Chemistry Experiments from an older cousin. Inspired by the book, he started working on various experiments, making use of various chemicals that could be found around in his house. After he spilled some potassium permanganate solution on his bedroom carpet his mother confined him to an alcove in the garage which he turned into a small laboratory , replete with industrial chemicals and second-hand laboratory glassware . Gunther was interested in finding out how things like detergents and oils were composed by cracking them in his fractionating column . He took particular interest in mixing paints for his art classes, as well as his chemistry classes in Balwyn High School . His father, being the Superintendent of Melbourne's electrical power station , borrowed an organic chemistry text from the chemists in the quality control laboratory. This ultimately led to an intense interest in synthesizing Azo dyes . At around age 14, Gunther attempted to predict the color of azo dyes based on the chromophore - auxochrome combination. Apart from drawing up empirical tables, this effort was largely unsuccessful due to his lack of knowledge of quantum theory .

Gunther taught physics at San Jose State University from 1980 to 1981.  He then joined Syncal Corporation , a small company contracted by NASA and JPL to develop thermoelectric materials for their deep-space missions. Gunther was asked to analyze the thermal stability test data from the Voyager RTGs . He discovered that the stability of the silicon - germanium (Si-Ge) thermoelectric alloy was controlled by a soliton -based precipitation mechanism. JPL used his work to select the next generation of RTG materials for the Galileo mission launched in 1989.

In 1982, Gunther joined Xerox PARC to develop parametric and functional test software for PARC's small-scale VLSI design fabrication line. Ultimately, he was recruited onto the Dragon multiprocessor workstation project where he also developed the PARCbench multiprocessor benchmark. This was his first foray into computer performance analysis.

1989, he developed a Wick-rotated version of Richard Feynman 's quantum path integral formalism for analyzing performance degradation in large-scale computer systems and packet networks.

In 1990 Gunther joined Pyramid Technology (now part of Fujitsu Siemens Computers) where he held positions as senior scientist and manager of the Performance Analysis Group that was responsible for attaining industry-high TPC benchmarks on their Unix multiprocessors. He also performed simulations for the design of the Reliant RM1000 parallel database server.

Gunther founded Performance Dynamics Company as a sole proprietorship, registered in California in 1994, to provide consulting and educational services for the management of high performance computer systems with an emphasis on performance analysis and enterprise-wide capacity planning . He went on to release and develop his own open-source performance modeling software called "PDQ (Pretty Damn Quick)" around 1998. That software also accompanied his first textbook on performance analysis entitled The Practical Performance Analyst . Several other books have followed since then.

In 2004, Gunther has embarked on joint research into quantum information systems based on photonics . During the course of his research in this area, he has developed a theory of photon bifurcation that is currently being tested experimentally at École Polytechnique Fédérale de Lausanne . This represents yet another application of path integral formulation to circumvent the wave-particle duality of light.

In its simplest rendition, this theory can be considered as providing the quantum corrections to the Abbe - Rayleigh diffraction theory of imaging and the Fourier theory of optical information processing .

Inspired by the work of Tukey , Gunther explored ways to help systems analyst visualize performance in a manner similar to that already available in scientific visualization and information visualization . In 1991, he developed a tool called Barry , which employs barycentric coordinates to visualize sampled CPU usage data on large-scale multiprocessor systems. More recently, he has applied the same 2- simplex barycentric coordinates to visualizing the Apdex application performance metric, which is based on categorical response time data. A barycentric 3-simplex (a tetrahedron ), that can be swivelled on the computer screen using a mouse , has been found useful for visualizing packet network performance data. In 2008, he co-founded the PerfViz google group .

The throughput capacity X(N) of a computational platform is given by:

X ( N ) = γ N 1 + α ( N − 1 ) + β N ( N − 1 ) {\displaystyle X(N)={\frac {\gamma N}{1+\alpha (N-1)+\beta N(N-1)}}}

where N represents either the number of physical processors in the hardware configuration or the number of users driving the software application. The parameters α {\displaystyle \alpha } , β {\displaystyle \beta } and γ {\displaystyle \gamma } respectively represent the levels of contention (e.g., queueing for shared resources), coherency delay (i.e., latency for data to become consistent) and concurrency (or effective parallelism) in the system. The β {\displaystyle \beta } parameter also quantifies the retrograde throughput seen in many stress tests but not accounted for in either Amdahl's law or event-based simulations .
This scalability law was originally developed by Gunther in 1993 while he was employed at Pyramid Technology . Since there are no topological dependencies, C(N) can model symmetric multiprocessors , multicores , clusters , and GRID architectures. Also, because each of the three terms has a definite physical meaning, they can be employed as a heuristic to determine where to make performance improvements in hardware platforms or software applications.

Having a high contention indicates sequential processing that could be parallelized, while having a high coherency suggests excessive dependencies among processes, prompting you to minimize interactions. Also, with help of this equation, you can, in advance, calculate the maximum effective capacity of your system: scaling up your system beyond that point is a waste.

At a more fundamental level, the above equation can be derived from the Machine Repairman queueing model:

Theorem (Gunther 2008): The universal scalability law is equivalent to the synchronous queueing bound on throughput in a modified Machine Repairman with state-dependent service times.

The following corollary (Gunther 2008 with β = 0 {\displaystyle \beta =0} ) corresponds to Amdahl's law:

Theorem (Gunther 2002): Amdahl's law for parallel speedup is equivalent to the synchronous queueing bound on throughput in a Machine Repairman model of a multiprocessor.

BSc Honors dissertation, department of physics, October (1974)

Heidelberg, Germany, October 2001, ISBN 3-540-42145-9 ( Contributed chapter )