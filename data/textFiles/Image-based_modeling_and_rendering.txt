In computer graphics and computer vision , image-based modeling and rendering ( IBMR ) methods rely on a set of two-dimensional images of a scene to generate a three-dimensional model and then render some novel views of this scene.

The traditional approach of computer graphics has been used to create a geometric model in 3D and try to reproject it onto a two-dimensional image.  Computer vision, conversely, is mostly focused on detecting, grouping, and extracting features (edges, faces, etc. ) present in a given picture and then trying to interpret them as three-dimensional clues.  Image-based modeling and rendering allows the use of multiple two-dimensional images in order to generate directly novel two-dimensional images, skipping the manual modeling stage.

Instead of considering only the physical model of a solid, IBMR methods usually focus more on light modeling.  The fundamental concept behind IBMR is the plenoptic illumination function which is a parametrisation of the light field . The plenoptic function describes the light rays contained in a given volume. It can be represented with seven dimensions: a ray is defined by its position ( x , y , z ) {\displaystyle (x,y,z)} , its orientation ( θ , ϕ ) {\displaystyle (\theta ,\phi )} , its wavelength ( λ ) {\displaystyle (\lambda )} and its time ( t ) {\displaystyle (t)} : P ( x , y , z , θ , ϕ , λ , t ) {\displaystyle P(x,y,z,\theta ,\phi ,\lambda ,t)} .  IBMR methods try to approximate the plenoptic function to render a novel set of two-dimensional images from another.  Given the high dimensionality of this function, practical methods place constraints on the parameters in order to reduce this number (typically to 2 to 4).