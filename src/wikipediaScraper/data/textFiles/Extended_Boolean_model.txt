The Extended Boolean model was described in a Communications of the ACM article appearing in 1983, by Gerard Salton, Edward A. Fox, and Harry Wu. The goal of the Extended Boolean model is to overcome the drawbacks of the Boolean model that has been used in information retrieval . The Boolean model doesn't consider term weights in queries, and the result set of a Boolean query is often either too small or too big. The idea of the extended model is to make use of partial matching and term weights as in the vector space model. It combines the characteristics of the Vector Space Model with the properties of Boolean algebra and ranks the similarity between queries and documents. This way a document may be somewhat relevant if it matches some of the queried terms and will be returned as a result, whereas in the Standard Boolean model it wasn't.

Thus, the extended Boolean model can be considered as a generalization of both the Boolean and vector space models; those two are special cases if suitable settings and definitions are employed. Further, research has shown effectiveness improves relative to that for Boolean query processing.  Other research has shown that relevance feedback and query expansion can be integrated with extended Boolean query processing.

In the Extended Boolean model , a document is represented as a vector (similarly to in the vector model). Each i dimension corresponds to a separate term associated with the document.

The weight of term K x associated with document d j is measured by its normalized Term frequency and can be defined as:

w x , j = f x , j ∗ I d f x m a x i I d f i {\displaystyle w_{x,j}=f_{x,j}*{\frac {Idf_{x}}{max_{i}Idf_{i}}}}

where Idf x is inverse document frequency and f x,j the term frequency for term x in document j.

The weight vector associated with document d j can be represented as:

v d j = [ w 1 , j , w 2 , j , … , w i , j ] {\displaystyle \mathbf {v} _{d_{j}}=[w_{1,j},w_{2,j},\ldots ,w_{i,j}]}

Considering the space composed of two terms K x and K y only, the corresponding term weights are w 1 and w 2 . Thus, for query q or = ( K x ∨ K y ) , we can calculate the similarity with the following formula:

s i m ( q o r , d ) = w 1 2 + w 2 2 2 {\displaystyle sim(q_{or},d)={\sqrt {\frac {w_{1}^{2}+w_{2}^{2}}{2}}}}

For query q and = ( K x ∧ K y ) , we can use:

s i m ( q a n d , d ) = 1 − ( 1 − w 1 ) 2 + ( 1 − w 2 ) 2 2 {\displaystyle sim(q_{and},d)=1-{\sqrt {\frac {(1-w_{1})^{2}+(1-w_{2})^{2}}{2}}}}

We can generalize the previous 2D extended Boolean model example to higher t-dimensional space using Euclidean distances.

This can be done using P-norms which extends the notion of distance to include p-distances, where 1 ≤ p ≤ ∞ is a new parameter.

: s i m ( q o r , d j ) = w 1 p + w 2 p + . . . . + w t p t p {\displaystyle sim(q_{or},d_{j})={\sqrt[{p}]{\frac {w_{1}^{p}+w_{2}^{p}+....+w_{t}^{p}}{t}}}}

Consider the query q = ( K 1 ∧ K 2 ) ∨ K 3 . The similarity between query q and document d can be computed using the formula:

s i m ( q , d ) = ( 1 − ( ( 1 − w 1 ) p + ( 1 − w 2 ) p 2 p ) ) p + w 3 p 2 p {\displaystyle sim(q,d)={\sqrt[{p}]{\frac {(1-{\sqrt[{p}]{({\frac {(1-w_{1})^{p}+(1-w_{2})^{p}}{2}}}}))^{p}+w_{3}^{p}}{2}}}}

Lee and Fox compared the Standard and Extended Boolean models with three test collections, CISI, CACM and INSPEC.
Using P-norms they obtained an average precision improvement of 79%, 106% and 210% over the Standard model, for the CISI, CACM and INSPEC collections, respectively. The P-norm model is computationally expensive because of the number of exponentiation operations that it requires but it achieves much better results than the Standard model and even Fuzzy retrieval techniques. The Standard Boolean model is still the most efficient.