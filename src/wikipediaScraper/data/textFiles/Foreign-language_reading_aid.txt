Computer-assisted language learning (CALL), known as computer-aided instruction (CAI) in British English and computer-aided language instruction (CALI) in American English, Levy (1997: p. 1) briefly defines it as "the exploration and study of computer applications in language teaching and learning." CALL embraces a wide range of information and communications technology "applications and approaches to teaching and learning foreign languages, ranging from the traditional drill-and-practice programs that characterized CALL in the 1960s and 1970s to more recent manifestations of CALL, such as those utilized virtual learning environment and Web-based distance learning . It also extends to the use of corpora and concordancers , interactive whiteboards, computer-mediated communication (CMC), language learning in virtual worlds , and mobile-assisted language learning (MALL) .

The term CALI (computer-assisted language instruction) was used before CALL, originating as a subset of the broader term CAI (computer-assisted instruction). CALI fell out of favor among language teachers, however, because it seemed to emphasize a teacher-centered instructional approach. Language teachers increasingly favored a student-centered approach focused on learning rather than instruction. CALL began to replace CALI in the early 1980s (Davies & Higgins, 1982: p. 3). and it is now incorporated into the names of the growing number of professional associations worldwide.

An alternative term, technology-enhanced language learning (TELL), also emerged around the early 1990s: e.g. the TELL Consortium project, University of Hull.

The current philosophy of CALL emphasizes student-centered materials that empower learners to work independently. These materials can be structured or unstructured but typically incorporate two key features: interactive and individualized learning. CALL employs tools that assist teachers in facilitating language learning, whether reinforcing classroom lessons or providing additional support to learners.The design of CALL materials typically integrates principles from language pedagogy and methodology, drawing from various learning theories such as behaviourism, cognitive theory, constructivism, and second-language acquisition theories like Stephen Krashen's. monitor hypothesis .

A combination of face-to-face teaching and CALL is usually referred to as blended learning . Blended learning is designed to increase learning potential and is more commonly found than pure CALL (Pegrum 2009: p. 27).

See Davies et al. (2011: Section 1.1, What is CALL? ). See also Levy & Hubbard (2005), who raise the question Why call CALL "CALL"?

CALL dates back to the 1960s, when it was first introduced on university mainframe computers. The PLATO project, initiated at the University of Illinois in 1960, is an important landmark in the early development of CALL (Marty 1981). The advent of the microcomputer in the late 1970s brought computing within the range of a wider audience, resulting in a boom in the development of CALL programs and a flurry of publications of books on CALL in the early 1980s.

Dozens of CALL programs are currently available on the internet, at prices ranging from free to expensive, and other programs are available only through university language courses.

There have been several attempts to document the history of CALL. Sanders (1995) covers the period from the mid-1960s to the mid-1990s, focusing on CALL in North America. Delcloque (2000) documents the history of CALL worldwide, from its beginnings in the 1960s to the dawning of the new millennium. Davies (2005) takes a look back at CALL's past and attempts to predict where it is going. Hubbard (2009) offers a compilation of 74 key articles and book excerpts, originally published in the years 1988–2007, that give a comprehensive overview of the wide range of leading ideas and research results that have exerted an influence on the development of CALL or that show promise in doing so in the future. A published review of Hubbard's collection can be found in Language Learning & Technology 14, 3 (2010).

Butler-Pascoe (2011) looks at the history of CALL from a different point of view, namely the evolution of CALL in the dual fields of educational technology and second/foreign language acquisition and the paradigm shifts experienced along the way.

See also Davies et al. (2011: Section 2, History of CALL ).

During the 1980s and 1990s, several attempts were made to establish a CALL typology. A wide range of different types of CALL programs was identified by Davies & Higgins (1985), Jones & Fortescue (1987), Hardisty & Windeatt (1989) and Levy (1997: pp. 118ff.). These included gap-filling and Cloze programs, multiple-choice programs, free-format (text-entry) programs, adventures and simulations, action mazes, sentence-reordering programs, exploratory programs—and "total Cloze", a type of program in which the learner has to reconstruct a whole text. Most of these early programs still exist in modernised versions.

Since the 1990s, it has become increasingly difficult to categorise CALL as it now extends to the use of blogs , wikis , social networking , podcasting , Web 2.0 applications, language learning in virtual worlds and interactive whiteboards (Davies et al. 2010: Section 3.7).

Warschauer (1996) and Warschauer & Healey (1998) took a different approach. Rather than focusing on the typology of CALL, they identified three historical phases of CALL, classified according to their underlying pedagogical and methodological approaches:

Most CALL programs in Warschauer & Healey's first phase, Behavioristic CALL (1960s to 1970s), consisted of drill-and-practice materials in which the computer presented a stimulus and the learner provided a response. At first, both could be done only through text. The computer would analyse students' input and give feedback, and more sophisticated programs would react to students' mistakes by branching to help screens and remedial activities. While such programs and their underlying pedagogy still exist today, behaviouristic approaches to language learning have been rejected by most language teachers, and the increasing sophistication of computer technology has led CALL to other possibilities.

The second phase described by Warschauer & Healey, Communicative CALL, is based on the communicative approach that became prominent in the late 1970s and 1980s (Underwood 1984). In the communicative approach the focus is on using the language rather than analysis of the language, and grammar is taught implicitly rather than explicitly. It also allows for originality and flexibility in student output of language. The communicative approach coincided with the arrival of the PC, which made computing much more widely available and resulted in a boom in the development of software for language learning. The first CALL software in this phase continued to provide skill practice but not in a drill format—for example: paced reading, text reconstruction and language games—but the computer remained the tutor. In this phase, computers provided context for students to use the language, such as asking for directions to a place, and programs not designed for language learning such as Sim City , Sleuth and Where in the World is Carmen Sandiego? were used for language learning. Criticisms of this approach include using the computer in an ad hoc and disconnected manner for more marginal aims rather than the central aims of language teaching.

The third phase of CALL described by Warschauer & Healey, Integrative CALL, starting from the 1990s, tried to address criticisms of the communicative approach by integrating the teaching of language skills into tasks or projects to provide direction and coherence. It also coincided with the development of multimedia technology (providing text, graphics, sound and animation) as well as Computer-mediated communication (CMC). CALL in this period saw a definitive shift from the use of the computer for drill and tutorial purposes (the computer as a finite, authoritative base for a specific task) to a medium for extending education beyond the classroom. Multimedia CALL started with interactive laser videodiscs such as Montevidisco (Schneider & Bennion 1984) and A la rencontre de Philippe (Fuerstenberg 1993), both of which were simulations of situations where the learner played a key role. These programs later were transferred to CD-ROMs, and new role-playing games (RPGs) such as Who is Oscar Lake? made their appearance in a range of different languages.

In a later publication Warschauer changed the name of the first phase of CALL from Behavioristic CALL to Structural CALL and also revised the dates of the three phases (Warschauer 2000):

Bax (2003) took issue with Warschauer & Haley (1998) and Warschauer (2000) and proposed these three phases:

See also Bax & Chambers (2006) and Bax (2011), in which the topic of "normalisation" is revisited.

A basic use of CALL is in vocabulary acquisition using flashcards , which requires quite simple programs. Such programs often make use of spaced repetition , a technique whereby the learner is presented with the vocabulary items that need to be committed to memory at increasingly longer intervals until long-term retention is achieved. This has led to the development of a number of applications known as spaced repetition systems (SRS), including the generic Anki or SuperMemo package and programs such as BYKI and phase-6, which have been designed specifically for learners of foreign languages.

Above all, careful consideration must be given to pedagogy in designing CALL software, but publishers of CALL software tend to follow the latest trend, regardless of its desirability. Moreover, approaches to teaching foreign languages are constantly changing, dating back to grammar-translation , through the direct method , audio-lingualism and a variety of other approaches, to the more recent communicative approach and constructivism (Decoo 2001).

Designing and creating CALL software is an extremely demanding task, calling upon a range of skills. Major CALL development projects are usually managed by a team of people:

CALL inherently supports learner autonomy , the final of the eight conditions that Egbert et al. (2007) cite as "Conditions for Optimal Language Learning Environments". Learner autonomy places the learner firmly in control so that he or she "decides on learning goals" (Egbert et al., 2007, p. 8).

It is all too easy when designing CALL software to take the comfortable route and produce a set of multiple-choice and gap-filling exercises, using a simple authoring tool (Bangs 2011), but CALL is much more than this; Stepp-Greany (2002), for example, describes the creation and management of an environment incorporating a constructivist and whole language philosophy. According to constructivist theory, learners are active participants in tasks in which they "construct" new knowledge derived from their prior experience. Learners also assume responsibility for their learning, and the teacher is a facilitator rather than a purveyor of knowledge. Whole language theory embraces constructivism and postulates that language learning moves from the whole to the part, rather than building sub-skills to lead towards the higher abilities of comprehension, speaking, and writing. It also emphasises that comprehending, speaking, reading, and writing skills are interrelated, reinforcing each other in complex ways. Language acquisition is, therefore, an active process in which the learner focuses on cues and meaning and makes intelligent guesses. Additional demands are placed upon teachers working in a technological environment incorporating constructivist and whole language theories. The development of teachers' professional skills must include new pedagogical as well as technical and management skills. Regarding the issue of teacher facilitation in such an environment, the teacher has a key role to play, but there could be a conflict between the aim to create an atmosphere for learner independence and the teacher's natural feelings of responsibility. In order to avoid learners' negative perceptions, Stepp-Greany points out that it is especially important for the teacher to continue to address their needs, especially those of low-ability learners.

Language teachers have been avid users of technology for a very long time. Gramophone records were among the first technological aids to be used by language teachers in order to present students with recordings of native speakers' voices, and broadcasts from foreign radio stations were used to make recordings on reel-to-reel tape recorders. Other examples of technological aids that have been used in the foreign language classroom include slide projectors, film-strip projectors, film projectors, videocassette recorders and DVD players. In the early 1960s, integrated courses (which were often described as multimedia courses) began to appear. Examples of such courses are Ecouter et Parler (consisting of a coursebook and tape recordings) and Deutsch durch die audiovisuelle Methode (consisting of an illustrated coursebook, tape recordings and a film-strip – based on the Structuro-Global Audio-Visual method).

During the 1970s and 1980s standard microcomputers were incapable of producing sound and they had poor graphics capability. This represented a step backwards for language teachers, who by this time had become accustomed to using a range of different media in the foreign language classroom. The arrival of the multimedia computer in the early 1990s was therefore a major breakthrough as it enabled text, images, sound and video to be combined in one device and the integration of the four basic skills of listening, speaking, reading and writing (Davies 2011: Section 1).

Examples of CALL programs for multimedia computers that were published on CD-ROM and DVD from the mid-1990s onwards are described by Davies (2010: Section 3). CALL programs are still being published on CD-ROM and DVD, but Web-based multimedia CALL has now virtually supplanted these media.

Following the arrival of multimedia CALL, multimedia language centres began to appear in educational institutions. While multimedia facilities offer many opportunities for language learning with the integration of text, images, sound and video, these opportunities have often not been fully utilised. One of the main promises of CALL is the ability to individualise learning but, as with the language labs that were introduced into educational institutions in the 1960s and 1970s, the use of the facilities of multimedia centres has often devolved into rows of students all doing the same drills (Davies 2010: Section 3.1). There is therefore a danger that multimedia centres may go the same way as the language labs. Following a boom period in the 1970s, language labs went rapidly into decline. Davies (1997: p. 28) lays the blame mainly on the failure to train teachers to use language labs, both in terms of operation and in terms of developing new methodologies, but there were other factors such as poor reliability, lack of materials and a lack of good ideas.

Managing a multimedia language centre requires not only staff who have a knowledge of foreign languages and language teaching methodology but also staff with technical know-how and budget management ability, as well as the ability to combine all these into creative ways of taking advantage of what the technology can offer. A centre manager usually needs assistants for technical support, for managing resources and even the tutoring of students. Multimedia centres lend themselves to self-study and potentially self-directed learning, but this is often misunderstood. The simple existence of a multimedia centre does not automatically lead to students learning independently. Significant investment of time is essential for materials development and creating an atmosphere conducive to self-study. Unfortunately, administrators often have the mistaken belief that buying hardware by itself will meet the needs of the centre, allocating 90% of its budget to hardware and virtually ignoring software and staff training needs (Davies et al. 2011: Foreword ). Self-access language learning centres or independent learning centres have emerged partially independently and partially in response to these issues. In self-access learning, the focus is on developing learner autonomy through varying degrees of self-directed learning, as opposed to (or as a complement to) classroom learning. In many centres learners access materials and manage their learning independently, but they also have access to staff for help. Many self-access centres are heavy users of technology and an increasing number of them are now offering online self-access learning opportunities. Some centres have developed novel ways of supporting language learning outside the context of the language classroom (also called 'language support') by developing software to monitor students' self-directed learning and by offering online support from teachers. Centre managers and support staff may need to have new roles defined for them to support students' efforts at self-directed learning: v. Mozzon-McPherson & Vismans (2001), who refer to a new job description, namely that of the "language adviser".

The emergence of the World Wide Web (now known simply as "the Web") in the early 1990s marked a significant change in the use of communications technology for all computer users. Email and other forms of electronic communication had been in existence for many years, but the launch of Mosaic , the first graphical Web browser , in 1993 brought about a radical change in the ways in which we communicate electronically. The launch of the Web in the public arena immediately began to attract the attention of language teachers. Many language teachers were already familiar with the concept of hypertext on stand-alone computers, which made it possible to set up non-sequential structured reading activities for language learners in which they could point to items of text or images on a page displayed on the computer screen and branch to any other pages, e.g. in a so-called "stack" as implemented in the HyperCard program on Apple Mac computers. The Web took this one stage further by creating a worldwide hypertext system that enabled the user to branch to different pages on computers anywhere in the world simply by pointing and clicking at a piece of text or an image. This opened up access to thousands of authentic foreign-language websites to teachers and students that could be used in a variety of ways. A problem that arose, however, was that this could lead to a good deal of time-wasting if Web browsing was used in an unstructured way (Davies 1997: pp. 42–43), and language teachers responded by developing more structured activities and online exercises (Leloup & Ponterio 2003). Davies (2010) lists over 500 websites, where links to online exercises can be found, along with links to online dictionaries and encyclopaedias, concordancers, translation aids and other miscellaneous resources of interest to the language teacher and learner.

The launch of the (free) Hot Potatoes (Holmes & Arneil) authoring tool, which was first demonstrated publicly at the EUROCALL 1998 conference, made it possible for language teachers to create their own online interactive exercises. Other useful tools are produced by the same authors.

In its early days the Web could not compete seriously with multimedia CALL on CD-ROM and DVD. Sound and video quality was often poor, and interaction was slow. But now the Web has caught up. Sound and video are of high quality and interaction has improved tremendously, although this does depend on sufficient bandwidth being available, which is not always the case, especially in remote rural areas and developing countries. One area in which CD-ROMs and DVDs are still superior is in the presentation of listen/respond/playback activities, although such activities on the Web are continually improving.

Since the early 2000s there has been a boom in the development of so-called Web 2.0 applications. Contrary to popular opinion, Web 2.0 is not a new version of the Web, rather it implies a shift in emphasis from Web browsing, which is essentially a one-way process (from the Web to the end-user), to making use of Web applications in the same way as one uses applications on a desktop computer. It also implies more interaction and sharing. Walker, Davies & Hewer (2011: Section 2.1) list the following examples of Web 2.0 applications that language teachers are using:

There is no doubt that the Web has proved to be a main focus for language teachers, who are making increasingly imaginative use of its wide range of facilities: see Dudeney (2007) and Thomas (2008). Above all, the use of Web 2.0 tools calls for a careful reexamination of the role of the teacher in the classroom (Richardson 2006).

Corpora have been used for many years as the basis of linguistic research and also for the compilation of dictionaries and reference works such as the Collins Cobuild series, published by HarperCollins. Tribble & Barlow (2001), Sinclair (2004) and McEnery & Wilson (2011) describe a variety of ways in which corpora can be used in language teaching.

An early reference to the use of electronic concordancers in language teaching can be found in Higgins & Johns (1984: pp. 88–94), and many examples of their practical use in the classroom are described by Lamy & Klarskov Mortensen (2010).

It was Tim Johns (1991), however, who raised the profile of the use of concordancers in the language classroom with his concept of Data-driven learning (DDL). DDL encourages learners to work out their own rules about the meaning of words and their usage by using a concordancer to locate examples in a corpus of authentic texts. It is also possible for the teacher to use a concordancer to find examples of authentic usage to demonstrate a point of grammar or typical collocations, and to generate exercises based on the examples found. Various types of concordancers and where they can be obtained are described by Lamy & Klarskov Mortensen (2011).

Robb (2003) shows how it is possible to use Google as a concordancer, but he also points out a number of drawbacks, for instance there is no control over the educational level, nationality, or other characteristics of the creators of the texts that are found, and the presentation of the examples is not as easy to read as the output of a dedicated concordancer that places the key words (i.e. the search terms) in context.

Virtual worlds date back to the adventure games and simulations of the 1970s, for example Colossal Cave Adventure , a text-only simulation in which the user communicated with the computer by typing commands at the keyboard. Language teachers discovered that it was possible to exploit these text-only programs by using them as the basis for discussion. Jones G. (1986) describes an experiment based on the Kingdom simulation, in which learners played roles as members of a council governing an imaginary kingdom. A single computer in the classroom was used to provide the stimulus for discussion, namely simulating events taking place in the kingdom: crop planting time, harvest time, unforeseen catastrophes, etc.

The early adventure games and simulations led on to multi-user variants, which were known as MUDs (Multi-user domains). Like their predecessors, MUDs were text-only, with the difference that they were available to a wider online audience. MUDs then led on to MOOs (Multi-user domains object-oriented), which language teachers were able to exploit for teaching foreign languages and intercultural understanding: see Donaldson & Kötter (1999) and (Shield 2003).

The next major breakthrough in the history of virtual worlds was the graphical user interface. Lucasfilm's Habitat (1986), was one of the first virtual worlds that was graphically based, albeit only in a two-dimensional environment. Each participant was represented by a visual avatar who could interact with other avatars using text chat.

Three-dimensional virtual worlds such as Traveler and Active Worlds , both of which appeared in the 1990s, were the next important development. Traveler included the possibility of audio communication (but not text chat) between avatars who were represented as disembodied heads in a three-dimensional abstract landscape. Svensson (2003) describes the Virtual Wedding Project, in which advanced students of English made use of Active Worlds as an arena for constructivist learning.

The 3D world of Second Life was launched in 2003. Initially perceived as another role-playing game (RPG), it began to attract the interest of language teachers with the launch of the first of the series of SLanguages conferences in 2007. Walker, Davies & Hewer (2011: Section 14.2.1) and Molka-Danielsen & Deutschmann (2010) describe a number of experiments and projects that focus on language learning in Second Life. See also the Wikipedia article Virtual world language learning .

To what extent Second Life and other virtual worlds will become established as important tools for teachers of foreign languages remains to be seen. It has been argued by Dudeney (2010) in his That's Life blog that Second Life is "too demanding and too unreliable for most educators". The subsequent discussion shows that this view is shared by many teachers, but many others completely disagree.

Regardless of the pros and cons of Second Life, language teachers' interest in virtual worlds continues to grow. The joint EUROCALL/CALICO Virtual Worlds Special Interest Group was set up in 2009, and there are now many areas in Second Life that are dedicated to language learning and teaching, for example the commercial area for learners of English, which is managed by Language Lab, and free areas such as the region maintained by the Goethe-Institut and the EduNation Islands. There are also examples of simulations created specifically for language education, such as those produced by the EC-funded NIFLAR and AVALON projects. NIFLAR is implemented both in Second Life and in Opensim .

Human language technologies (HLT) comprise a number of areas of research and development that focus on the use of technology to facilitate communication in a multilingual information society. Human language technologies are areas of activity in departments of the European Commission that were formerly grouped under the heading language engineering (Gupta & Schulze 2011: Section 1.1).

The parts of HLT that is of greatest interest to the language teacher is natural language processing (NLP), especially parsing , as well as the areas of speech synthesis and speech recognition .

Speech synthesis has improved immeasurably in recent years. It is often used in electronic dictionaries to enable learners to find out how words are pronounced. At word level, speech synthesis is quite effective, the artificial voice often closely resembling a human voice. At phrase level and sentence level, however, there are often problems of intonation, resulting in speech production that sounds unnatural even though it may be intelligible. Speech synthesis as embodied in text to speech (TTS) applications is invaluable as a tool for unsighted or partially sighted people. Gupta & Schulze (2010: Section 4.1) list several examples of speech synthesis applications.

Speech recognition is less advanced than speech synthesis. It has been used in a number of CALL programs, in which it is usually described as automatic speech recognition (ASR). ASR is not easy to implement. Ehsani & Knodt (1998) summarise the core problem as follows:

"Complex cognitive processes account for the human ability to associate acoustic signals with meanings and intentions. For a computer, on the other hand, speech is essentially a series of digital values. However, despite these differences, the core problem of speech recognition is the same for both humans and machines: namely, of finding the best match between a given speech sound and its corresponding word string. Automatic speech recognition technology attempts to simulate and optimize this process computationally."

Programs embodying ASR normally provide a native speaker model that the learner is requested to imitate, but the matching process is not 100% reliable and may result in a learner's perfectly intelligible attempt to pronounce a word or phrase being rejected (Davies 2010: Section 3.4.6 and Section 3.4.7).

Parsing is used in a number of ways in CALL. Gupta & Schulze (2010: Section 5) describe how parsing may be used to analyse sentences, presenting the learner with a tree diagram that labels the constituent parts of speech of a sentence and shows the learner how the sentence is structured.

Parsing is also used in CALL programs to analyse the learner's input and diagnose errors. Davies (2002) writes:

"Discrete error analysis and feedback were a common feature of traditional CALL, and the more sophisticated programs would attempt to analyse the learner's response, pinpoint errors, and branch to help and remedial activities. ... Error analysis in CALL is, however, a matter of controversy. Practitioners who come into CALL via the disciplines of computational linguistics , e.g. Natural Language Processing (NLP) and Human Language Technologies (HLT), tend to be more optimistic about the potential of error analysis by computer than those who come into CALL via language teaching. [...] An alternative approach is the use of Artificial Intelligence (AI) techniques to parse the learner's response – so-called intelligent CALL (ICALL) – but there is a gulf between those who favour the use of AI to develop CALL programs (Matthews 1994) and, at the other extreme, those who perceive this approach as a threat to humanity (Last 1989:153)".

Underwood (1989) and Heift & Schulze (2007) present a more positive picture of AI.

Research into speech synthesis, speech recognition and parsing and how these areas of NLP can be used in CALL are the main focus of the NLP Special Interest Group within the EUROCALL professional association and the ICALL Special Interest Group within the CALICO professional association. The EUROCALL NLP SIG also maintains a Ning.

The question of the impact of CALL in language learning and teaching has been raised at regular intervals ever since computers first appeared in educational institutions (Davies & Hewer 2011: Section 3). Recent large-scale impact studies include the study edited by Fitzpatrick & Davies (2003) and the EACEA (2009) study, both of which were produced for the European Commission.

A distinction needs to be made between the impact and the effectiveness of CALL. Impact may be measured quantitatively and qualitatively in terms of the uptake and use of ICT in teaching foreign languages, issues of availability of hardware and software, budgetary considerations, Internet access, teachers' and learners' attitudes to the use of CALL, changes in the ways in which languages are learnt and taught, and paradigm shifts in teachers' and learners' roles. Effectiveness, on the other hand, usually focuses on assessing to what extent ICT is a more effective way of teaching foreign languages compared to using traditional methods – and this is more problematic as so many variables come into play. Worldwide, the picture of the impact of CALL is extremely varied. Most developed nations work comfortably with the new technologies, but developing nations are often beset with problems of costs and broadband connectivity. Evidence on the effectiveness of CALL – as with the impact of CALL – is extremely varied and many research questions still need to be addressed and answered. Hubbard (2002) presents the results of a CALL research survey that was sent to 120 CALL professionals from around the world asking them to articulate a CALL research question they would like to see answered. Some of the questions have been answered but many more remain open. Leakey (2011) offers an overview of current and past research in CALL and proposes a comprehensive model for evaluating the effectiveness of CALL platforms, programs and pedagogy.

A crucial issue is the extent to which the computer is perceived as taking over the teacher's role. Warschauer (1996: p. 6) perceived the computer as playing an "intelligent" role, and claimed that a computer program "should ideally be able to understand a user's spoken input and evaluate it not just for correctness but also for appropriateness. It should be able to diagnose a student's problems with pronunciation, syntax, or usage and then intelligently decide among a range of options (e.g. repeating, paraphrasing, slowing down, correcting, or directing the student to background explanations)." Jones C. (1986), on the other hand, rejected the idea of the computer being "some kind of inferior teacher-substitute" and proposed a methodology that focused more on what teachers could do with computer programs rather than what computer programs could do on their own: "in other words, treating the computer as they would any other classroom aid". Warschauer's high expectations in 1996 have still not been fulfilled, and currently there is an increasing tendency for teachers to go down the route proposed by Jones, making use of a variety of new tools such as corpora and concordancers , interactive whiteboards and applications for online communication.

Since the advent of the Web there has been an explosion in online learning, but to what extent it is effective is open to criticism. Felix (2003) takes a critical look at popular myths attached to online learning from three perspectives, namely administrators, teachers and students. She concludes: "That costs can be saved in this ambitious enterprise is clearly a myth, as are expectations of saving time or replacing staff with machines."

As for the effectiveness of CALL in promoting the four skills, Felix (2008) claims that there is "enough data in CALL to suggest positive effects on spelling, reading and writing", but more research is needed in order to determine its effectiveness in other areas, especially speaking online. She claims that students' perceptions of CALL are positive, but she qualifies this claim by stating that the technologies need to be stable and well supported, drawing attention to concerns that technical problems may interfere with the learning process. She also points out that older students may not feel comfortable with computers and younger students may not possess the necessary meta-skills for coping effectively in the challenging new environments. Training in computer literacy for both students and teachers is essential, and time constraints may pose additional problems. In order to achieve meaningful results she recommends "time-series analysis in which the same group of students is involved in experimental and control treatment for a certain amount of time and then switched – more than once if possible".

Types of technology training in CALL for language teaching professionals certainly vary. Within second language teacher education programs, namely pre-service course work, we can find "online courses along with face-to-face courses", computer technology incorporated into a more general second language education course, "technology workshops","a series of courses offered throughout the teacher education programs, and even courses specifically designed for a CALL certificate and a CALL graduate degree" The Organization for Economic Cooperation and Development has identified four levels of courses with only components, namely "web-supplemented, web-dependent, mixed mod and fully online".

There is a rapidly growing interest in resources about the use of technology to deliver CALL. Journals that have issues that "deal with how teacher education programs help prepare language teachers to use technology in their own classrooms" include Language Learning and Technology (2002), Innovations in Language Learning and Teaching (2009) and the TESOL international professional association's publication of technology standards for TESOL includes a chapter on preparation of teacher candidates in technology use, as well as the upgrading of teacher educators to be able to provide such instruction. Both CALICO and EUROCALL have special interest groups for teacher education in CALL.

The following professional associations are dedicated to the promulgation of research, development and practice relating to the use of new technologies in language learning and teaching. Most of them organise conferences and publish journals on CALL.