In computer programming , a trait is a language concept that represents a set of methods that can be used to extend the functionality of a class .

In object-oriented programming, behavior is sometimes shared between classes which are not related to each other. For example, many unrelated classes may have methods to serialize objects to JSON . Historically, there have been several approaches to solve this without duplicating the code in every class needing the behavior. Other approaches include multiple inheritance and mixins , but these have drawbacks: the behavior of the code may unexpectedly change if the order in which the mixins are applied is altered, or if new methods are added to the parent classes or mixins.

Traits solve these problems by allowing classes to use the trait and get the desired behavior. If a class uses more than one trait, the order in which the traits are used does not matter. The methods provided by the traits have direct access to the data of the class.

Traits combine aspects of protocols (interfaces) and mixins . Like an interface, a trait defines one or more method signatures , of which implementing classes must provide implementations. Like a mixin, a trait provides additional behavior for the implementing class.

In case of a naming collision between methods provided by different traits, the programmer must explicitly disambiguate which one of those methods will be used in the class; thus manually solving the diamond problem of multiple inheritance . This is different from other composition methods in object-oriented programming, where conflicting names are automatically resolved by scoping rules .

Operations which can be performed with traits include:

If a method is excluded from a trait, that method must be provided by the class that consumes the trait, or by a parent class of that class. This is because the methods provided by the trait might call the excluded method.

Trait composition is commutative (i.e. given traits A and B , A + B is equivalent to B + A ) and associative (i.e. given traits A , B , and C , ( A + B ) + C is equivalent to A + ( B + C )).

While traits offer significant advantages over many alternatives, they do have their own limitations.

If a trait requires the consuming class to provide certain methods, the trait cannot know if those methods are semantically equivalent to the trait's needs. For some dynamic languages, such as Perl, the required method can only be identified by a method name, not a full method signature , making it harder to guarantee that the required method is appropriate.

If a method is excluded from a trait, that method becomes a 'required' method for the trait because the trait's other methods might call it.

Traits come originally from the programming language Self and are supported by the following programming languages:

On C# 8.0, it is possible to define an implementation as a member of an interface.

This example uses a trait to enhance other classes:

This allows simulating aspects of multiple inheritance:

A trait in Rust declares a set of methods that a type must implement. Rust compilers require traits to be explicated, which ensures the safety of generics in Rust.

To simplify tedious and repeated implementation of traits like Debug and Ord , the derive macro can be used to request compilers to generate certain implementations automatically. Derivable traits include: Clone , Copy , Debug , Default , PartialEq , Eq , PartialOrd , Ord and Hash .