DNA profiling (also called DNA fingerprinting and genetic fingerprinting ) is the process of determining an individual's deoxyribonucleic acid ( DNA ) characteristics. DNA analysis intended to identify a species, rather than an individual, is called DNA barcoding .

DNA profiling is a forensic technique in criminal investigations , comparing criminal suspects' profiles to DNA evidence so as to assess the likelihood of their involvement in the crime. It is also used in paternity testing , to establish immigration eligibility, and in genealogical and medical research. DNA profiling has also been used in the study of animal and plant populations in the fields of zoology, botany, and agriculture.

Starting in the mid 1970s, scientific advances allowed the use of DNA as a material for the identification of an individual. The first patent covering the direct use of DNA variation for forensics ( US5593832A ) was filed by Jeffrey Glassberg in 1983, based upon work he had done while at Rockefeller University in the United States in 1981.

British geneticist Sir Alec Jeffreys independently developed a process for DNA profiling in 1985 while working in the Department of Genetics at the University of Leicester . Jeffreys discovered that a DNA examiner could establish patterns in unknown DNA. These patterns were a part of inherited traits that could be used to advance the field of relationship analysis. These discoveries lead to the first use of DNA profiling in a criminal case.

The process, developed by Jeffreys in conjunction with Peter Gill and Dave Werrett of the Forensic Science Service (FSS), was first used forensically in the solving of the murder of two teenagers who had been raped and murdered in Narborough, Leicestershire in 1983 and 1986. In the murder inquiry, led by Detective David Baker, the DNA contained within blood samples obtained voluntarily from around 5,000 local men who willingly assisted Leicestershire Constabulary with the investigation, resulted in the exoneration of Richard Buckland, an initial suspect who had confessed to one of the crimes, and the subsequent conviction of Colin Pitchfork on January 2, 1988. Pitchfork, a local bakery employee, had coerced his coworker Ian Kelly to stand in for him when providing a blood sample—Kelly then used a forged passport to impersonate Pitchfork. Another coworker reported the deception to the police. Pitchfork was arrested, and his blood was sent to Jeffreys' lab for processing and profile development. Pitchfork's profile matched that of DNA left by the murderer which confirmed Pitchfork's presence at both crime scenes; he pleaded guilty to both murders. After some years, a chemical company named Imperial Chemical Industries (ICI) introduced the first ever commercially available kit to the world. Despite being a relatively recent field, it had a significant global influence on both criminal justice system and society.

Although 99.9% of human DNA sequences are the same in every person, enough of the DNA is different that it is possible to distinguish one individual from another, unless they are monozygotic (identical) twins . DNA profiling uses repetitive sequences that are highly variable, called variable number tandem repeats (VNTRs), in particular short tandem repeats (STRs), also known as microsatellites , and minisatellites . VNTR loci are similar between closely related individuals, but are so variable that unrelated individuals are unlikely to have the same VNTRs.

Before VNTRs and STRs, people like Jeffreys used a process called restriction fragment length polymorphism (RFLP) . This process regularly used large portions of DNA to analyze the differences between two DNA samples. RFLP was among the first technologies used in DNA profiling and analysis. However, as technology has evolved, new technologies, like STR, emerged and took the place of older technology like RFLP.

The admissibility of DNA evidence in courts was disputed in the United States in the 1980s and 1990s, but has since become more universally accepted due to improved techniques.

When a sample such as blood or saliva is obtained, the DNA is only a small part of what is present in the sample. Before the DNA can be analyzed, it must be extracted from the cells and purified. There are many ways this can be accomplished, but all methods follow the same basic procedure. The cell and nuclear membranes need to be broken up to allow the DNA to be free in solution. Once the DNA is free, it can be separated from all other cellular components. After the DNA has been separated in solution, the remaining cellular debris can then be removed from the solution and discarded, leaving only DNA. The most common methods of DNA extraction include organic extraction (also called phenol chloroform extraction), Chelex extraction , and solid phase extraction . Differential extraction is a modified version of extraction in which DNA from two different types of cells can be separated from each other before being purified from the solution. Each method of extraction works well in the laboratory, but analysts typically select their preferred method based on factors such as the cost, the time involved, the quantity of DNA yielded, and the quality of DNA yielded.

RFLP stands for restriction fragment length polymorphism and, in terms of DNA analysis, describes a DNA testing method which utilizes restriction enzymes to "cut" the DNA at short and specific sequences throughout the sample. To start off processing in the laboratory, the sample has to first go through an extraction protocol, which may vary depending on the sample type or laboratory SOPs (Standard Operating Procedures). Once the DNA has been "extracted" from the cells within the sample and separated away from extraneous cellular materials and any nucleases that would degrade the DNA, the sample can then be introduced to the desired restriction enzymes to be cut up into discernable fragments. Following the enzyme digestion, a Southern Blot is performed. Southern Blots are a size-based separation method that are performed on a gel with either radioactive or chemiluminescent probes. RFLP could be conducted with single-locus or multi-locus probes (probes which target either one location on the DNA or multiple locations on the DNA). Incorporating the multi-locus probes allowed for higher discrimination power for the analysis, however completion of this process could take several days to a week for one sample due to the extreme amount of time required by each step required for visualization of the probes.

This technique was developed in 1983 by Kary Mullis. PCR is now a common and important technique used in medical and biological research labs for a variety of applications.

PCR, or Polymerase Chain Reaction, is a widely used molecular biology technique to amplify a specific DNA sequence.

Amplification is achieved by a series of three steps:

1- Denaturation : In this step, the DNA is heated to 95 °C to dissociate the hydrogen bonds between the complementary base pairs of the double-stranded DNA.

2-Annealing : During this stage the reaction is cooled to 50-65 °C . This enables the primers to attach to a specific location on the single -stranded template DNA by way of hydrogen bonding.

3-Extension : A thermostable DNA polymerase which is Taq polymerase is commonly used at this step. This is done at a temperature of 72 °C . DNA polymerase adds nucleotides in the 5'-3' direction and synthesizes the complementary strand of the DNA template .

The system of DNA profiling used today is based on polymerase chain reaction (PCR) and uses simple sequences.

From country to country, different STR-based DNA-profiling systems are in use. In North America, systems that amplify the CODIS 20 core loci are almost universal, whereas in the United Kingdom the DNA-17 loci system is in use, and Australia uses 18 core markers.

The true power of STR analysis is in its statistical power of discrimination. Because the 20 loci that are currently used for discrimination in CODIS are independently assorted (having a certain number of repeats at one locus does not change the likelihood of having any number of repeats at any other locus), the product rule for probabilities can be applied. This means that, if someone has the DNA type of ABC, where the three loci were independent, then the probability of that individual having that DNA type is the probability of having type A times the probability of having type B times the probability of having type C. This has resulted in the ability to generate match probabilities of 1 in a quintillion (1x10 ) or more. However, DNA database searches showed much more frequent than expected false DNA profile matches.

Due to the paternal inheritance, Y-haplotypes provide information about the genetic ancestry of the male population. To investigate this population history, and to provide estimates for haplotype frequencies in criminal casework, the "Y haplotype reference database (YHRD)" has been created in 2000 as an online resource. It currently comprises more than 300,000 minimal (8 locus) haplotypes from world-wide populations.

mtDNA can be obtained from such material as hair shafts and old bones/teeth. Control mechanism based on interaction point with data. This can be determined by tooled placement in sample.

When people think of DNA analysis, they often think about television shows like NCIS or CSI , which portray DNA samples coming into a lab and being instantly analyzed, followed by the pulling up of a picture of the suspect within minutes⁠. However, the reality is quite different, and perfect DNA samples are often not collected from the scene of a crime. Homicide victims are frequently left exposed to harsh conditions before they are found, and objects that are used to commit crimes have often been handled by more than one person. The two most prevalent issues that forensic scientists encounter when analyzing DNA samples are degraded samples and DNA mixtures.

Before modern PCR methods existed, it was almost impossible to analyze degraded DNA samples. Methods like Restriction fragment length polymorphism (RFLP), which was the first technique used for DNA analysis in forensic science, required high molecular weight DNA in the sample in order to get reliable data. High molecular weight DNA, however, is lacking in degraded samples, as the DNA is too fragmented to carry out RFLP accurately. It was only when Polymerase Chain Reaction techniques were invented that analysis of degraded DNA samples were able to be carried out. Multiplex PCR in particular made it possible to isolate and to amplify the small fragments of DNA that are still left in degraded samples. When multiplex PCR methods are compared to the older methods like RFLP, a vast difference can be seen. Multiplex PCR can theoretically amplify less than 1 ng of DNA, but RFLP had to have a least 100 ng of DNA in order to carry out an analysis.

Low-template DNA can happen when there is less than 0.1 ng( ) of DNA in a sample. This can lead to more stochastic effects (random events) such as allelic dropout or allelic drop-in which can alter the interpretation of a DNA profile. These stochastic effects can lead to the unequal amplification of the 2 alleles that come from a heterozygous individual. It is especially important to take low-template DNA into account when dealing with a mixture of DNA sample. This is because for one (or more) of the contributors in the mixture, they are more likely to have less than the optimal amount of DNA for the PCR reaction to work properly. Therefore, stochastic thresholds are developed for DNA profile interpretation. The stochastic threshold is the minimum peak height (RFU value), seen in an electropherogram where dropout occurs. If the peak height value is above this threshold, then it is reasonable to assume that allelic dropout has not occurred. For example, if only 1 peak is seen for a particular locus in the electropherogram but its peak height is above the stochastic threshold, then we can reasonably assume that this individual is homozygous and is not missing its heterozygous partner allele that otherwise would have dropped out due to having low-template DNA. Allelic dropout can occur when there is low-template DNA because there is such little DNA to start with that at this locus the contributor to the DNA sample (or mixture) is a true heterozygote but the other allele is not amplified and so it would be lost. Allelic drop-in can also occur when there is low-template DNA because sometimes the stutter peak can be amplified. The stutter is an artifact of PCR. During the PCR reaction, DNA Polymerase will come in and add nucleotides off of the primer, but this whole process is very dynamic, meaning that the DNA Polymerase is constantly binding, popping off and then rebinding. Therefore, sometimes DNA Polymerase will rejoin at the short tandem repeat ahead of it, leading to a short tandem repeat that is 1 repeat less than the template. During PCR, if DNA Polymerase happens to bind to a locus in stutter and starts to amplify it to make lots of copies, then this stutter product will appear randomly in the electropherogram, leading to allelic drop-in.

In instances in which DNA samples are degraded, like if there are intense fires or all that remains are bone fragments, standard STR testing on those samples can be inadequate. When standard STR testing is done on highly degraded samples, the larger STR loci often drop out, and only partial DNA profiles are obtained. Partial DNA profiles can be a powerful tool, but the probability of a random match is larger than if a full profile was obtained. One method that has been developed to analyse degraded DNA samples is to use miniSTR technology. In the new approach, primers are specially designed to bind closer to the STR region.

In normal STR testing, the primers bind to longer sequences that contain the STR region within the segment. MiniSTR analysis, however, targets only the STR location, which results in a DNA product that is much smaller.

By placing the primers closer to the actual STR regions, there is a higher chance that successful amplification of this region will occur. Successful amplification of those STR regions can now occur, and more complete DNA profiles can be obtained.  The success that smaller PCR products produce a higher success rate with highly degraded samples was first reported in 1995, when miniSTR technology was used to identify victims of the Waco fire.

Mixtures are another common issue faced by forensic scientists when they are analyzing unknown or questionable DNA samples. A mixture is defined as a DNA sample that contains two or more individual contributors. That can often occur when a DNA sample is swabbed from an item that is handled by more than one person or when a sample contains both the victim's and the assailant's DNA. The presence of more than one individual in a DNA sample can make it challenging to detect individual profiles, and interpretation of mixtures should be performed only by highly trained individuals. Mixtures that contain two or three individuals can be interpreted with difficulty. Mixtures that contain four or more individuals are much too convoluted to get individual profiles. One common scenario in which a mixture is often obtained is in the case of sexual assault. A sample may be collected that contains material from the victim, the victim's consensual sexual partners, and the perpetrator(s).

Mixtures can generally be sorted into three categories: Type A, Type B, and Type C. Type A mixtures have alleles with similar peak-heights all around, so the contributors cannot be distinguished from each other. Type B mixtures can be deconvoluted by comparing peak-height ratios to determine which alleles were donated together. Type C mixtures cannot be safely interpreted with current technology because the samples were affected by DNA degradation or having too small a quantity of DNA present.

When looking at an electropherogram, it is possible to determine the number of contributors in less complex mixtures based on the number of peaks located in each locus. In comparison to a single source profile, which will only have one or two peaks at each locus, a mixture is when there are three or more peaks at two or more loci. If there are three peaks at only a single locus, then it is possible to have a single contributor who is tri-allelic at that locus. Two person mixtures will have between two and four peaks at each locus, and three person mixtures will have between three and six peaks at each locus. Mixtures become increasingly difficult to deconvolute as the number of contributors increases.

As detection methods in DNA profiling advance, forensic scientists are seeing more DNA samples that contain mixtures, as even the smallest contributor can now be detected by modern tests. The ease in which forensic scientists have in interpenetrating DNA mixtures largely depends on the ratio of DNA present from each individual, the genotype combinations, and the total amount of DNA amplified. The DNA ratio is often the most important aspect to look at in determining whether a mixture can be interpreted. For example, if a DNA sample had two contributors, it would be easy to interpret individual profiles if the ratio of DNA contributed by one person was much higher than the second person. When a sample has three or more contributors, it becomes extremely difficult to determine individual profiles. Fortunately, advancements in probabilistic genotyping may make that sort of determination possible in the future. Probabilistic genotyping uses complex computer software to run through thousands of mathematical computations to produce statistical likelihoods of individual genotypes found in a mixture.

DNA profiling in plant:

Plant DNA profiling (fingerprinting) is a method for identifying cultivars that uses molecular marker techniques. This method is gaining attention due to Trade Related Intellectual property rights (TRIPs) and the Convention on Biological Diversity (CBD).

Advantages of Plant DNA profiling:

Identification, authentication, specific distinction, detecting adulteration and identifying phytoconstituents are all possible with DNA fingerprinting in medical plants.

DNA based markers are critical for these applications, determining the future of scientific study in pharmacognosy.

It also helps with determining the traits (such as seed size and leaf color) are likely to improve the offspring or not.

An early application of a DNA database was the compilation of a Mitochondrial DNA Concordance, prepared by Kevin W. P. Miller and John L. Dawson at the University of Cambridge from 1996 to 1999 from data collected as part of Miller's PhD thesis. There are now several DNA databases in existence around the world. Some are private, but most of the largest databases are government-controlled. The United States maintains the largest DNA database , with the Combined DNA Index System (CODIS) holding over 13 million records as of May 2018. The United Kingdom maintains the National DNA Database (NDNAD), which is of similar size, despite the UK's smaller population. The size of this database, and its rate of growth, are giving concern to civil liberties groups in the UK, where police have wide-ranging powers to take samples and retain them even in the event of acquittal. The Conservative–Liberal Democrat coalition partially addressed these concerns with part 1 of the Protection of Freedoms Act 2012 , under which DNA samples must be deleted if suspects are acquitted or not charged, except in relation to certain (mostly serious or sexual) offenses. Public discourse around the introduction of advanced forensic techniques (such as genetic genealogy using public genealogy databases and DNA phenotyping approaches) has been limited, disjointed, unfocused, and raises issues of privacy and consent that may warrant the establishment of additional legal protections.

The U.S. Patriot Act of the United States provides a means for the U.S. government to get DNA samples from suspected terrorists. DNA information from crimes is collected and deposited into the CODIS database, which is maintained by the FBI . CODIS enables law enforcement officials to test DNA samples from crimes for matches within the database, providing a means of finding specific biological profiles associated with collected DNA evidence.

When a match is made from a national DNA databank to link a crime scene to an offender having provided a DNA sample to a database, that link is often referred to as a cold hit . A cold hit is of value in referring the police agency to a specific suspect but is of less evidential value than a DNA match made from outside the DNA Databank.

FBI agents cannot legally store DNA of a person not convicted of a crime. DNA collected from a suspect not later convicted must be disposed of and not entered into the database. In 1998, a man residing in the UK was arrested on accusation of burglary. His DNA was taken and tested, and he was later released. Nine months later, this man's DNA was accidentally and illegally entered in the DNA database. New DNA is automatically compared to the DNA found at cold cases and, in this case, this man was found to be a match to DNA found at a rape and assault case one year earlier. The government then prosecuted him for these crimes. During the trial the DNA match was requested to be removed from the evidence because it had been illegally entered into the database. The request was carried out. The DNA of the perpetrator, collected from victims of rape, can be stored for years until a match is found. In 2014, to address this problem, Congress extended a bill that helps states deal with "a backlog" of evidence.

DNA profiling databases in Plants:

PIDS:

PIDS(Plant international DNA-fingerprinting system) is an open source web server and free software based plant international DNA fingerprinting system.

It manages huge amount of microsatellite DNA fingerprint data, performs genetic studies, and automates collection, storage and maintenance while decreasing human error and increasing efficiency.

The system may be tailored to specific laboratory needs, making it a valuable tool for plant breeders, forensic science, and human fingerprint recognition.

It keeps track of experiments, standardizes data and promotes inter-database communication.

It also helps with the regulation of variety quality, the preservation of variety rights and the use of molecular markers in breeding by providing location statistics, merging, comparison and genetic analysis function.

When using RFLP , the theoretical risk of a coincidental match is 1 in 100 billion (100,000,000,000) although the practical risk is actually 1 in 1,000 because monozygotic twins are 0.2% of the human population. Moreover, the rate of laboratory error is almost certainly higher than that and actual laboratory procedures often do not reflect the theory under which the coincidence probabilities were computed. For example, coincidence probabilities may be calculated based on the probabilities that markers in two samples have bands in precisely the same location, but a laboratory worker may conclude that similar but not precisely-identical band patterns result from identical genetic samples with some imperfection in the agarose gel. However, in that case, the laboratory worker increases the coincidence risk by expanding the criteria for declaring a match. Studies conducted in the 2000s quoted relatively-high error rates, which may be cause for concern. In the early days of genetic fingerprinting, the necessary population data to compute a match probability accurately was sometimes unavailable. Between 1992 and 1996, arbitrary-low ceilings were controversially put on match probabilities used in RFLP analysis, rather than the higher theoretically computed ones.

It is possible to use DNA profiling as evidence of genetic relationship although such evidence varies in strength from weak to positive. Testing that shows no relationship is absolutely certain. Further, while almost all individuals have a single and distinct set of genes, ultra-rare individuals, known as " chimeras ", have at least two different sets of genes. There have been two cases of DNA profiling that falsely suggested that a mother was unrelated to her children.

The functional analysis of genes and their coding sequences ( open reading frames [ORFs]) typically requires that each ORF be expressed, the encoded protein purified, antibodies produced, phenotypes examined, intracellular localization determined, and interactions with other proteins sought. In a study conducted by the life science company Nucleix and published in the journal Forensic Science International , scientists found that an in vitro synthesized sample of DNA matching any desired genetic profile can be constructed using standard molecular biology techniques without obtaining any actual tissue from that person.

Familial DNA searching (sometimes referred to as "familial DNA" or "familial DNA database searching") is the practice of creating new investigative leads in cases where DNA evidence found at the scene of a crime (forensic profile) strongly resembles that of an existing DNA profile (offender profile) in a state DNA database but there is not an exact match. After all other leads have been exhausted, investigators may use specially developed software to compare the forensic profile to all profiles taken from a state's DNA database to generate a list of those offenders already in the database who are most likely to be a very close relative of the individual whose DNA is in the forensic profile.

Familial DNA database searching was first used in an investigation leading to the conviction of Jeffrey Gafoor of the murder of Lynette White in the United Kingdom on 4 July 2003. DNA evidence was matched to Gafoor's nephew, who at 14 years old had not been born at the time of the murder in 1988. It was used again in 2004 to find a man who threw a brick from a motorway bridge and hit a lorry driver, killing him. DNA found on the brick matched that found at the scene of a car theft earlier in the day, but there were no good matches on the national DNA database. A wider search found a partial match to an individual; on being questioned, this man revealed he had a brother, Craig Harman, who lived very close to the original crime scene. Harman voluntarily submitted a DNA sample, and confessed when it matched the sample from the brick. As of 2011, familial DNA database searching is not conducted on a national level in the United States, where states determine how and when to conduct familial searches. The first familial DNA search with a subsequent conviction in the United States was conducted in Denver , Colorado, in 2008, using software developed under the leadership of Denver District Attorney Mitch Morrissey and Denver Police Department Crime Lab Director Gregg LaBerge. California was the first state to implement a policy for familial searching under then-Attorney General Jerry Brown , who later became Governor. In his role as consultant to the Familial Search Working Group of the California Department of Justice , former Alameda County Prosecutor Rock Harmon is widely considered to have been the catalyst in the adoption of familial search technology in California. The technique was used to catch the Los Angeles serial killer known as the " Grim Sleeper " in 2010. It was not a witness or informant that tipped off law enforcement to the identity of the "Grim Sleeper" serial killer, who had eluded police for more than two decades, but DNA from the suspect's own son. The suspect's son had been arrested and convicted in a felony weapons charge and swabbed for DNA the year before. When his DNA was entered into the database of convicted felons, detectives were alerted to a partial match to evidence found at the "Grim Sleeper" crime scenes. David Franklin Jr., also known as the Grim Sleeper, was charged with ten counts of murder and one count of attempted murder. More recently, familial DNA led to the arrest of 21-year-old Elvis Garcia on charges of sexual assault and false imprisonment of a woman in Santa Cruz in 2008. In March 2011 Virginia Governor Bob McDonnell announced that Virginia would begin using familial DNA searches.

At a press conference in Virginia on 7 March 2011, regarding the East Coast Rapist , Prince William County prosecutor Paul Ebert and Fairfax County Police Detective John Kelly said the case would have been solved years ago if Virginia had used familial DNA searching. Aaron Thomas, the suspected East Coast Rapist, was arrested in connection with the rape of 17 women from Virginia to Rhode Island, but familial DNA was not used in the case.

Critics of familial DNA database searches argue that the technique is an invasion of an individual's 4th Amendment rights. Privacy advocates are petitioning for DNA database restrictions, arguing that the only fair way to search for possible DNA matches to relatives of offenders or arrestees would be to have a population-wide DNA database. Some scholars have pointed out that the privacy concerns surrounding familial searching are similar in some respects to other police search techniques, and most have concluded that the practice is constitutional. The Ninth Circuit Court of Appeals in United States v. Pool (vacated as moot) suggested that this practice is somewhat analogous to a witness looking at a photograph of one person and stating that it looked like the perpetrator, which leads law enforcement to show the witness photos of similar looking individuals, one of whom is identified as the perpetrator.

Critics also state that racial profiling could occur on account of familial DNA testing. In the United States, the conviction rates of racial minorities are much higher than that of the overall population. It is unclear whether this is due to discrimination from police officers and the courts, as opposed to a simple higher rate of offence among minorities. Arrest-based databases, which are found in the majority of the United States, lead to an even greater level of racial discrimination. An arrest, as opposed to conviction, relies much more heavily on police discretion.

For instance, investigators with Denver District Attorney's Office successfully identified a suspect in a property theft case using a familial DNA search. In this example, the suspect's blood left at the scene of the crime strongly resembled that of a current Colorado Department of Corrections prisoner.

Partial DNA matches are the result of moderate stringency CODIS searches that produce a potential match that shares at least one allele at every locus . Partial matching does not involve the use of familial search software, such as those used in the United Kingdom and the United States, or additional Y-STR analysis and therefore often misses sibling relationships. Partial matching has been used to identify suspects in several cases in both countries and has also been used as a tool to exonerate the falsely accused. Darryl Hunt was wrongly convicted in connection with the rape and the murder of a young woman in 1984 in North Carolina .

Police forces may collect DNA samples without a suspect's knowledge, and use it as evidence. The legality of the practice has been questioned in Australia .

In the United States , where it has been accepted, courts often rule that there is no expectation of privacy and cite California v. Greenwood (1988), in which the Supreme Court held that the Fourth Amendment does not prohibit the warrantless search and seizure of garbage left for collection outside the curtilage of a home . Critics of this practice underline that this analogy ignores that "most people have no idea that they risk surrendering their genetic identity to the police by, for instance, failing to destroy a used coffee cup. Moreover, even if they do realize it, there is no way to avoid abandoning one's DNA in public."

The United States Supreme Court ruled in Maryland v. King (2013) that DNA sampling of prisoners arrested for serious crimes is constitutional.

In the United Kingdom , the Human Tissue Act 2004 prohibits private individuals from covertly collecting biological samples (hair, fingernails, etc.) for DNA analysis but exempts medical and criminal investigations from the prohibition.

Evidence from an expert who has compared DNA samples must be accompanied by evidence as to the sources of the samples and the procedures for obtaining the DNA profiles. The judge must ensure that the jury must understand the significance of DNA matches and mismatches in the profiles. The judge must also ensure that the jury does not confuse the match probability (the probability that a person that is chosen at random has a matching DNA profile to the sample from the scene) with the probability that a person with matching DNA committed the crime. In 1996 R v. Doheny

Juries should weigh up conflicting and corroborative evidence, using their own common sense and not by using mathematical formulae, such as Bayes' theorem , so as to avoid "confusion, misunderstanding and misjudgment".

In R v Bates , Moore-Bick LJ said:

We can see no reason why partial profile DNA evidence should not be admissible provided that the jury are made aware of its inherent limitations and are given a sufficient explanation to enable them to evaluate it. There may be cases where the match probability in relation to all the samples tested is so great that the judge would consider its probative value to be minimal and decide to exclude the evidence in the exercise of his discretion, but this gives rise to no new question of principle and can be left for decision on a case by case basis. However, the fact that there exists in the case of all partial profile evidence the possibility that a "missing" allele might exculpate the accused altogether does not provide sufficient grounds for rejecting such evidence. In many there is a possibility (at least in theory) that evidence that would assist the accused and perhaps even exculpate him altogether exists, but that does not provide grounds for excluding relevant evidence that is available and otherwise admissible, though it does make it important to ensure that the jury are given sufficient information to enable them to evaluate that evidence properly.

There are state laws on DNA profiling in all 50 states of the United States . Detailed information on database laws in each state can be found at the National Conference of State Legislatures website.

In August 2009, scientists in Israel raised serious doubts concerning the use of DNA by law enforcement as the ultimate method of identification. In a paper published in the journal Forensic Science International: Genetics , the Israeli researchers demonstrated that it is possible to manufacture DNA in a laboratory, thus falsifying DNA evidence. The scientists fabricated saliva and blood samples, which originally contained DNA from a person other than the supposed donor of the blood and saliva.

The researchers also showed that, using a DNA database, it is possible to take information from a profile and manufacture DNA to match it, and that this can be done without access to any actual DNA from the person whose DNA they are duplicating. The synthetic DNA oligos required for the procedure are common in molecular laboratories.

The New York Times quoted the lead author, Daniel Frumkin, saying, "You can just engineer a crime scene ... any biology undergraduate could perform this". Frumkin perfected a test that can differentiate real DNA samples from fake ones. His test detects epigenetic modifications, in particular, DNA methylation . Seventy percent of the DNA in any human genome is methylated, meaning it contains methyl group modifications within a CpG dinucleotide context. Methylation at the promoter region is associated with gene silencing. The synthetic DNA lacks this epigenetic modification, which allows the test to distinguish manufactured DNA from genuine DNA.

It is unknown how many police departments, if any, currently use the test. No police lab has publicly announced that it is using the new test to verify DNA results.

Researchers at the University of Tokyo integrated an artificial DNA replication scheme with a rebuilt gene expression system and micro-compartmentalization utilizing cell-free materials alone for the first time. Multiple cycles of serial dilution were performed on a system contained in microscale water-in-oil droplets.

Chances of making DNA change on purpose

Overall, this study's artificial genomic DNA, which kept copying itself using self-encoded proteins and made its sequence better on its own, is a good starting point for making more complex artificial cells. By adding the genes needed for transcription and translation to artificial genomic DNA, it may be possible in the future to make artificial cells that can grow on their own when fed small molecules like amino acids and nucleotides. Using living organisms to make useful things, like drugs and food, would be more stable and easier to control in these artificial cells.

On July 7, 2008, the American chemical society reported that Japanese chemists have created the world's first DNA molecule comprised nearly completely of synthetic components.

A nano-particle based artificial transcription factor for gene regulation:

Nano Script is a nanoparticle-based artificial transcription factor that is supposed to replicate the structure and function of TFs. On gold nanoparticles, functional peptides and tiny molecules referred to as synthetic transcription factors, which imitate the various TF domains, were attached to create Nano Script. We show that Nano Script localizes to the nucleus and begins transcription of a reporter plasmid by an amount more than 15-fold. Moreover, Nano Script can successfully transcribe targeted genes onto endogenous DNA in a nonviral manner.

Three different fluorophores—red, green, and blue—were carefully fixed on the DNA rod surface to provide spatial information and create a nanoscale barcode. Epifluorescence and total internal reflection fluorescence microscopy reliably deciphered spatial information between fluorophores. By moving the three fluorophores on the DNA rod, this nanoscale barcode created 216 fluorescence patterns.

DNA testing has been used to establish the right of succession to British titles.

Cases: